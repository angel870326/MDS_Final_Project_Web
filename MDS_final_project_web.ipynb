{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angel870326/MDS_Final_Project_Web/blob/main/MDS_final_project_web.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1FWjFHjPpNl"
      },
      "source": [
        "> 2022.12.22 Ssu-Yun Wang<br/>\n",
        "[Github @angel870326](https://github.com/angel870326)\n",
        "\n",
        "# **Manufacturing Data Science Final Project Web**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcOOpwEEqpNa",
        "outputId": "d4e7dc53-093b-4327-b21f-6c7061e58bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# sConnect to the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC59khfKJrMj"
      },
      "source": [
        "## **Installation & Setup (Flask & Ngrok)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TefBH-gbm1mM",
        "outputId": "87b88db4-e57c-4f99-9823-42d05d06df5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (1.1.4)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from flask) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from flask) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from flask) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from flask) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->flask) (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.8/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.8/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask\n",
        "!pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYvUJ0fRKFUJ"
      },
      "source": [
        "Get your AuthToken from ngrok using this link: https://dashboard.ngrok.com/get-started/your-authtoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytLgTlggqGci",
        "outputId": "a1842ba4-a59f-4c33-b488-759b93597a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok==4.1.1 in /usr/local/lib/python3.8/dist-packages (4.1.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyngrok==4.1.1) (6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from pyngrok==4.1.1) (0.16.0)\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok==4.1.1\n",
        "!ngrok authtoken '1qCRUUcFgnhlSf0o5xS5eilRUUk_7mexMJwXSwcCcPEuvCs2q' # your authtoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyJKCLmxaYfL"
      },
      "source": [
        "Bootstrap (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_W9EK45aaj4",
        "outputId": "635cfeea-3f04-4520-d2fa-723d3d455204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bootstrap-flask in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: WTForms in /usr/local/lib/python3.8/dist-packages (from bootstrap-flask) (3.0.1)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.8/dist-packages (from bootstrap-flask) (1.1.4)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask->bootstrap-flask) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from Flask->bootstrap-flask) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from Flask->bootstrap-flask) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask->bootstrap-flask) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->bootstrap-flask) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install bootstrap-flask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoUmEPpnSOWg"
      },
      "source": [
        "## **Variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cWaF_wqeclA4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MofMSJ6JSTez"
      },
      "outputs": [],
      "source": [
        "# feature_list = [[2, 'Starch Flow'],\n",
        "#                 [3, 'Amina Flow'],\n",
        "#                 [5, 'Ore Pulp pH'],\n",
        "#                 [6, 'Ore Pulp Density'],\n",
        "#                 [7, 'Flotation Column 01 Air Flow'],\n",
        "#                 [12, 'Flotation Column 06 Air Flow'],\n",
        "#                 [16, 'Flotation Column 03 Level'],\n",
        "#                 [17, 'Flotation Column 04 Level'],\n",
        "#                 [18, 'Flotation Column 05 Level'],\n",
        "#                 [20, 'Flotation Column 07 Level']]\n",
        "\n",
        "# feature_list = [2, 3, 5, 6, 7, 12, 16, 17, 18, 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "guTdRlPxWpsh"
      },
      "outputs": [],
      "source": [
        "labels = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4AgSix911V4R"
      },
      "outputs": [],
      "source": [
        "df_demo = pd.DataFrame()\n",
        "values = []\n",
        "hint = \"\"\n",
        "upper_bound = 4.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JAg9c8S16YP"
      },
      "source": [
        "## **Model**\n",
        "\n",
        "by 陳志剛 & [Meng-Chieh, Liu](https://github.com/MengChiehLiu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZHjOcShGsDl"
      },
      "source": [
        "### (1) Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPmpwgVCGtKD",
        "outputId": "006a5f58-8268-4a36-d155-3bf816293368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.1.3 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = joblib.load(\"/content/gdrive/MyDrive/碩二上/製造數據科學/MDS_Final_Project_Web_v5/static/model/scaler.save\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lzm2evPFNDbo"
      },
      "outputs": [],
      "source": [
        "def make_data(data, timestep = 45, data_type = 'x'):\n",
        "    query_dim = 2\n",
        "    if data_type == 'x':\n",
        "        assert data.ndim == query_dim\n",
        "        return (np.array([data[i:i+timestep] for i in range(data.shape[0]-(2*timestep))]))\n",
        "    elif data_type == 'y':\n",
        "        assert data.ndim == query_dim\n",
        "        return (np.array([data[i+timestep:i+(2*timestep)] for i in range(data.shape[0]-(2*timestep))]))\n",
        "    else:\n",
        "        print('incorrect data type')\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEB-Kf7KPoqg"
      },
      "source": [
        "### (2) Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h4EVq4LjPqwv"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "class MDSDataset(Dataset):\n",
        "    def __init__(self, x, y=None, new_y=None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.new_y = new_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if(self.y is not None and self.new_y is not None):\n",
        "          return torch.FloatTensor(self.x[idx]), torch.FloatTensor(self.y[idx]), torch.FloatTensor(self.new_y[idx])\n",
        "        else:\n",
        "          return torch.FloatTensor(self.x[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "leo9iM1lSX4p"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "class MDSDataset(Dataset):\n",
        "    def __init__(self, x, y=None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if(self.y is not None):\n",
        "          return torch.FloatTensor(self.x[idx]), torch.FloatTensor(self.y[idx])\n",
        "        else:\n",
        "          return torch.FloatTensor(self.x[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BagFC5J9nz9"
      },
      "source": [
        "### (3) Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT6FralETfPZ"
      },
      "source": [
        "#### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3S8cZfhTTn-e"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, feature_size, hid_dim, n_layers, dropout):\n",
        "    super().__init__()\n",
        "    self.n_layers = n_layers\n",
        "    self.rnn = nn.GRU(feature_size, hid_dim, n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n",
        "    # self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, input):\n",
        "    # outputs, hidden = self.rnn(torch.from_numpy(input.astype(np.float32)))  # 先轉成 float32 再轉成 tensor\n",
        "    outputs, hidden = self.rnn(input)\n",
        "    # print(\"Encoder outpupt shape:\", outputs.shape)\n",
        "    # print(\"Encoder output hidden shape:\", hidden.shape)\n",
        "    hidden = hidden.view(self.n_layers, 2, input.shape[0], -1)\n",
        "    # print(\"Split two direction hidden state:\", hidden.shape)\n",
        "\n",
        "    # Concat\n",
        "    hidden = torch.cat((hidden[:, -2, :, :], hidden[:, -1, :, :]), dim=2)\n",
        "    # print(\"Concat hidden state:\", hidden.shape)\n",
        "\n",
        "    # outputs 是最上層RNN的輸出        \n",
        "    return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AwxQUaNTvsY"
      },
      "source": [
        "#### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lGP2hC2qTx4-"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.value = nn.Parameter(torch.rand(self.hidden_size * 2))\n",
        "    self.linear = nn.Linear(self.hidden_size * 2 * 2, self.hidden_size * 2)\n",
        "    self.atten_weights = None\n",
        "    self.time_step = 45\n",
        "  \n",
        "  def forward(self, encoder_outputs, decoder_hidden):\n",
        "    h = decoder_hidden[0].repeat(self.time_step, 1, 1).transpose(0,1)\n",
        "    attn_weights = self.dot(encoder_outputs, h) # the dot have done the softmax\n",
        "    self.atten_weights = attn_weights\n",
        "    return attn_weights\n",
        "\n",
        "  def dot(self, encoder_outputs, decoder_hidden):\n",
        "    '''\n",
        "    dot product\n",
        "    encoder_outputs: BxTxH\n",
        "    decoder_hidden: BxH -> BxHx1 # decoder_hidden: NxBxH -> NxBxHx1\n",
        "    attention_scores: BxTx1 -> BxT # attention_scores: NxBxTx1 -> NxBxT\n",
        "    v: H -> BxH -> BxHx1\n",
        "    '''\n",
        "    \n",
        "    # print(\"encoder_outputs:\", encoder_outputs.shape)\n",
        "    # print(\"decoder_hidden:\", decoder_hidden.shape)\n",
        "    attn = self.linear(torch.cat([encoder_outputs, decoder_hidden], 2))\n",
        "    # print(\"attn:\", attn.shape)\n",
        "    v = self.value.repeat(encoder_outputs.shape[0], 1).unsqueeze(2)\n",
        "    # print(\"v:\", v.shape)\n",
        "    attention_scores = torch.bmm(attn, v).squeeze(2)\n",
        "    # softmax to normalization\n",
        "    # attention_weights: BxT -> Bx1xT\n",
        "    attention_weights = F.softmax(attention_scores, dim=1)\n",
        "    # print(\"attention_weights:\", attention_weights.shape)\n",
        "    return attention_weights.unsqueeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxUU8EIDT1aK"
      },
      "source": [
        "#### Decoder "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zpOOVVMjT3LA"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, feature_size, hid_dim, n_layers, dropout, isatt):\n",
        "    super().__init__()\n",
        "    self.n_layers = n_layers\n",
        "    self.hid_dim = hid_dim * 2 # Bidirection 要* 2\n",
        "\n",
        "    # Attention\n",
        "    self.isatt = isatt\n",
        "    self.attention = Attention(hid_dim)\n",
        "    self.rnn = nn.GRU(self.hid_dim + 1, self.hid_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "    self.dense1 = nn.Linear(in_features=self.hid_dim ,out_features=self.hid_dim//2)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.drop1 = nn.Dropout(0.3)\n",
        "    self.dense2 = nn.Linear(in_features=self.hid_dim//2 ,out_features=self.hid_dim//4)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.drop2 = nn.Dropout(0.3)   \n",
        "    self.dense3 = nn.Linear(in_features=self.hid_dim//4 ,out_features=1)\n",
        "    # self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, input, hidden, encoder_outputs):\n",
        "    # input = [batch size, vocab size]\n",
        "    # hidden = [batch size, n layers * directions, hid dim]\n",
        "\n",
        "    if self.isatt:\n",
        "      attn = self.attention(encoder_outputs, hidden)\n",
        "      # print(\"Attention weights shape:\", attn.shape)\n",
        "      # print(\"Attention weights :\", attn)\n",
        "      # print(\"encoder_outputs:\", encoder_outputs.shape)\n",
        "      context_vector = torch.bmm(attn, encoder_outputs)\n",
        "      # print(\"context_vector:\", context_vector.shape)\n",
        "      rnn_input = torch.cat([context_vector, input.unsqueeze(1)], dim=2) # H+1\n",
        "      # print(\"rnn_input:\", rnn_input.shape)\n",
        "\n",
        "    output, hidden = self.rnn(rnn_input, hidden)\n",
        "    # print(\"Decoder_rnn_outputs shape:\",output.shape) # output = [batch size, 1, hid dim]\n",
        "    # print(\"Decoder_rnn_hidden shape\", hidden.shape) # hidden = [num_layers, batch size, hid dim]\n",
        "    \n",
        "    output = self.dense1(output.squeeze(1))\n",
        "    # output = self.relu1(output)\n",
        "    output = self.drop1(output)\n",
        "    output = self.dense2(output)\n",
        "    # output = self.relu2(output)\n",
        "    output = self.drop2(output)\n",
        "    prediciton = self.dense3(output)   \n",
        "\n",
        "    return prediciton, hidden, attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-aNlpDjUHYg"
      },
      "source": [
        "#### Seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eMx27d3EUD3R"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, time_step):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.time_step = time_step\n",
        "            \n",
        "  def forward(self, input, target, isInitial=False):\n",
        "    # input  = [batch size, input len, vocab size]\n",
        "    # target = [batch size, target len, vocab size]\n",
        "\n",
        "    # Encoder\n",
        "    encoder_outputs, encoder_hidden = self.encoder(input) # hidden state already concat\n",
        "\n",
        "    # preds = []\n",
        "    preds = torch.zeros(self.time_step, input.shape[0], 1)\n",
        "    for i in range(0, self.time_step):\n",
        "      # decoder input\n",
        "      decoder_input = target[:, i]\n",
        "      if (i == 0):  # 第一次用 encoder 的 hidden，因為第一個 decoder 的 hidden state 是由 encoder 傳過來的\n",
        "        decoder_outputs, decoder_hidden, attn = self.decoder(decoder_input, encoder_hidden, encoder_outputs)       \n",
        "      else:         # 之後用自己的hidden\n",
        "        decoder_outputs, decoder_hidden, attn = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      \n",
        "      if(isInitial and i < self.time_step-1):\n",
        "        target[:, i+1] = decoder_outputs\n",
        "              \n",
        "      # print(\"Decoder_outputs shape:\",decoder_outputs.shape)\n",
        "      # print(\"Decoder_hidden shape\", decoder_hidden.shape)\n",
        "      preds[i] = decoder_outputs\n",
        "\n",
        "    if(isInitial):\n",
        "      return target, attn.reshape(attn.shape[0], attn.shape[2]).tolist()\n",
        "    else:\n",
        "      return preds, attn.reshape(attn.shape[0], attn.shape[2]).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvQTx-fOKpxT"
      },
      "source": [
        "### (4) GA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZPRhGYClZ5mE"
      },
      "outputs": [],
      "source": [
        "class GeneticAlgorithm():\n",
        "  def __init__(self, data_1, data_2, upper_bound, population_size:int = 100, crossover_rate:float = 1, mutate_rate:float = 0.02):\n",
        "    self.features_name = {1: 'Starch Flow',\n",
        "                          2: 'Amina Flow',\n",
        "                          3: 'Ore Pulp pH',\n",
        "                          4: 'Ore Pulp Density',\n",
        "                          5: 'Flotation Column 01 Air Flow',\n",
        "                          6: 'Flotation Column 06 Air Flow',\n",
        "                          7: 'Flotation Column 03 Level',\n",
        "                          8: 'Flotation Column 04 Level',\n",
        "                          9: 'Flotation Column 05 Level',\n",
        "                          10: 'Flotation Column 07 Level'}\n",
        "    self.features_id = {1:2, 2:3, 3:5, 4:6, 5:7, 6:12, 7:16, 8:17, 9:18, 10:20}\n",
        "    self.threshold = upper_bound\n",
        "    \n",
        "    self.data_1 = data_1\n",
        "    self.data_2 = data_2\n",
        "\n",
        "    self.population_size = population_size\n",
        "    self.crossover_rate = crossover_rate\n",
        "    self.mutate_rate = mutate_rate\n",
        "\n",
        "    self.population = {}\n",
        "    self.seen = set()\n",
        "\n",
        "    self.best_fitness = np.inf\n",
        "    self.best_solution = None\n",
        "\n",
        "  @staticmethod\n",
        "  def encode(sloution: list) -> str:\n",
        "    return '_'.join([str(i) for i in sloution])\n",
        "\n",
        "  @staticmethod\n",
        "  def decode(sloution: str) -> list:\n",
        "    return [int(i) for i in sloution.split('_')]\n",
        "\n",
        "  def get_fitness(self, solution: list, data_1: torch.Tensor, data_2:torch.Tensor) -> float:\n",
        "    # clone and \n",
        "    data_1 = data_1.clone()\n",
        "    data_1 = scaler.inverse_transform(data_1[0])\n",
        "\n",
        "    # reformat_solution\n",
        "    solution_dict = {i:0 for i in range(1, 11)}\n",
        "    for unit in solution:\n",
        "      if unit != 0:\n",
        "        solution_dict[abs(unit)] += unit/abs(unit)\n",
        "    \n",
        "    # check maximum and update data\n",
        "    for key, value in solution_dict.items():\n",
        "      original_value = data_1[-1][self.features_id[key]]\n",
        "      data_1[-1][self.features_id[key]] *= 1+solution_dict[key]/100\n",
        "\n",
        "    data_1 = torch.FloatTensor(scaler.transform(data_1).reshape(1, 45, 21))\n",
        "    # calculate score\n",
        "    test_pred, _ = sq2sq_model2(data_1.cuda(), data_2.cuda())\n",
        "    score = test_pred[-1][0].item()\n",
        "    return score\n",
        "\n",
        "  def initialize(self):\n",
        "    while len(self.population) < self.population_size:\n",
        "      solution = [random.randint(-10, 10) for i in range(10)]\n",
        "      solution.sort()\n",
        "      encode_solution = self.encode(solution)\n",
        "      \n",
        "      if encode_solution not in self.seen:\n",
        "        fitness = self.get_fitness(solution, self.data_1, self.data_2)\n",
        "        self.population[encode_solution] = fitness\n",
        "        self.seen.add(encode_solution)\n",
        "\n",
        "        if fitness < self.best_fitness:\n",
        "          self.best_fitness = fitness\n",
        "          self.best_solution = encode_solution\n",
        "\n",
        "  @staticmethod\n",
        "  def crossover(solution_1: list, solution_2: list) -> list:\n",
        "    random.shuffle(solution_1)\n",
        "    random.shuffle(solution_2)\n",
        "\n",
        "    new_sloution = solution_1[:5] + solution_2[5:]\n",
        "\n",
        "    return new_sloution\n",
        "\n",
        "  def mutate(self, solution: list) -> list:\n",
        "    for i, unit in enumerate(solution):\n",
        "      if random.random() < self.mutate_rate:\n",
        "        solution[i] = random.randint(-10, 10)\n",
        "    solution.sort()\n",
        "    return solution\n",
        "\n",
        "  def generate(self):\n",
        "    next_generation = {}\n",
        "    new_population = {}\n",
        "    best_solution = None\n",
        "    best_fitness = np.inf\n",
        "\n",
        "    solutions, weights = zip(*self.population.items())\n",
        "    weights = 1 / np.array(weights, dtype=float)\n",
        "    probs = weights / sum(weights)\n",
        "\n",
        "    while len(next_generation) < self.population_size:\n",
        "      # crossover\n",
        "      if random.random() < self.crossover_rate:\n",
        "        parent1, parent2 = np.random.choice(solutions, 2, p=probs)\n",
        "        child = self.crossover(self.decode(parent1), self.decode(parent2))\n",
        "        \n",
        "        # mutate\n",
        "        child = self.mutate(child)\n",
        "        encode_child = self.encode(child)\n",
        "        if encode_child not in self.seen:\n",
        "          fitness = self.get_fitness(child, self.data_1, self.data_2)\n",
        "\n",
        "          next_generation[encode_child] = fitness\n",
        "          self.seen.add(encode_child)\n",
        "\n",
        "          if fitness < best_fitness:\n",
        "              best_solution = encode_child\n",
        "              best_fitness = fitness\n",
        "\n",
        "    # update best fitness\n",
        "    if best_fitness < self.best_fitness:\n",
        "      self.best_solution = best_solution\n",
        "      self.best_fitness = best_fitness\n",
        "\n",
        "    # selection\n",
        "    while len(new_population) < self.population_size:\n",
        "        solution1 = random.choice(list(self.population.keys()))\n",
        "        solution2 = random.choice(list(next_generation.keys()))\n",
        "        fitness_1 = self.population.pop(solution1)\n",
        "        fitness_2 = next_generation.pop(solution2)\n",
        "        if fitness_1 < fitness_2:\n",
        "            new_population[solution1] = fitness_1\n",
        "        else:\n",
        "            new_population[solution2] = fitness_2\n",
        "    \n",
        "    self.population = new_population\n",
        "  \n",
        "  def translate(self, solution: str):\n",
        "    suggest = {i:0 for i in self.features_name.values()}\n",
        "    \n",
        "    for unit in self.decode(solution):\n",
        "      if unit > 0:\n",
        "        suggest[self.features_name[abs(unit)]] += 1\n",
        "      elif unit < 0:\n",
        "        suggest[self.features_name[abs(unit)]] -= 1\n",
        "\n",
        "    hint = ''\n",
        "    for (feature, adjustment) in suggest.items():\n",
        "      hint+= f\"{feature}: {adjustment}%\\n\"\n",
        "\n",
        "    return hint\n",
        "\n",
        "  def optimize(self, max_iteration=5, early_stopping=True):\n",
        "    start_time = time.time()\n",
        "    current_best = self.best_fitness\n",
        "    patience = 0\n",
        "\n",
        "    for i in range(max_iteration):\n",
        "      self.generate()\n",
        "      if self.best_fitness < current_best:\n",
        "        current_best = self.best_fitness\n",
        "        patience = 0\n",
        "      else:\n",
        "        patience+=1\n",
        "\n",
        "      if early_stopping and (patience==5 or self.best_fitness < self.threshold):\n",
        "        break\n",
        "\n",
        "    hint = self.translate(self.best_solution)\n",
        "    return self.best_fitness, hint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6iBhbvG-mvj"
      },
      "source": [
        "### (5) Optimization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN4L2nzBIS72",
        "outputId": "765500d3-b003-4a43-eac0-afabf698fbe0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Load model\n",
        "batch_size = 128\n",
        "time_step = 45\n",
        "encoder = Encoder(21, 128, 3, 0.3)\n",
        "decoder = Decoder(21, 128, 3, 0.3, True) \n",
        "sq2sq_model2 = Seq2Seq(encoder, decoder, time_step).cuda()\n",
        "sq2sq_model2.load_state_dict(torch.load(\"/content/gdrive/MyDrive/碩二上/製造數據科學/MDS_Final_Project_Web_v5/static/model/model.pt\")) #改路徑"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YSICR2GM9NWT"
      },
      "outputs": [],
      "source": [
        "def predictor(df: pd.DataFrame) -> tuple:\n",
        "  x_val_shift = make_data(df.iloc[:, :-1], timestep = 45, data_type = 'x')\n",
        "  y_val_shift = make_data(df.iloc[:, -1:], timestep = 45, data_type = 'y')\n",
        "  val_set = MDSDataset(x_val_shift, y_val_shift)\n",
        "  val_loader = DataLoader(val_set, batch_size = 1, shuffle=False)\n",
        "\n",
        "  original = []\n",
        "  new = []\n",
        "  upper_bound = 4.5\n",
        "  hint = None\n",
        "\n",
        "  sq2sq_model2.eval()\n",
        "  with torch.no_grad():\n",
        "    for i, (data_1, data_2) in enumerate(tqdm(val_loader)):\n",
        "      if(i == 0):\n",
        "        val_pred, attn_w = sq2sq_model2(data_1.cuda(), data_2.cuda())\n",
        "        val_decoder_input = torch.FloatTensor(val_pred.transpose(0,1))\n",
        "        score = val_pred[-1][0].item()\n",
        "        original.append(score)\n",
        "        new.append(score)\n",
        "      else:\n",
        "        val_pred, attn_w = sq2sq_model2(data_1.cuda(), val_decoder_input.cuda())\n",
        "        score = val_pred[-1][0].item()\n",
        "        original.append(score)\n",
        "        if score > upper_bound:\n",
        "          GA = GeneticAlgorithm(data_1, val_decoder_input, upper_bound)\n",
        "          GA.initialize()\n",
        "          new_score, hint = GA.optimize(max_iteration=5, early_stopping=False)\n",
        "          new.append(new_score)\n",
        "          break\n",
        "        else:\n",
        "          new.append(score)\n",
        "        val_decoder_input = torch.FloatTensor(val_pred.transpose(0,1))\n",
        " \n",
        "  return original, new, hint, upper_bound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QcfROU25DSwn"
      },
      "outputs": [],
      "source": [
        "def adjuster(df: pd.DataFrame, adjustments: list) -> list:\n",
        "  x_val_shift = make_data(df.iloc[:, :-1], timestep = 45, data_type = 'x')\n",
        "  y_val_shift = make_data(df.iloc[:, -1:], timestep = 45, data_type = 'y')\n",
        "  val_set = MDSDataset(x_val_shift, y_val_shift)\n",
        "  val_loader = DataLoader(val_set, batch_size = 1, shuffle=False)\n",
        "\n",
        "  features_id = [2, 3, 5, 6, 7, 12, 16, 17, 18, 20]\n",
        "  scores = []\n",
        "\n",
        "  sq2sq_model2.eval()\n",
        "  with torch.no_grad():\n",
        "    for i, (data_1, data_2) in enumerate(tqdm(val_loader)):\n",
        "      if(i == 0):\n",
        "        val_pred, attn_w = sq2sq_model2(data_1.cuda(), data_2.cuda())\n",
        "        val_decoder_input = torch.FloatTensor(val_pred.transpose(0,1))\n",
        "      else:\n",
        "        if i == len(val_loader) -1:\n",
        "          data_1 = scaler.inverse_transform(data_1[0])\n",
        "          for j, adjustment in enumerate(adjustments):\n",
        "            data_1[-1][features_id[j]] *= 1+adjustment/100\n",
        "          data_1 = torch.FloatTensor(scaler.transform(data_1).reshape(-1, data_1.shape[0], data_1.shape[1]))\n",
        "\n",
        "        val_pred, attn_w = sq2sq_model2(data_1.cuda(), val_decoder_input.cuda())\n",
        "        val_decoder_input = torch.FloatTensor(val_pred.transpose(0,1))\n",
        "          \n",
        "      score = val_pred[-1][0].item()\n",
        "      scores.append(score)\n",
        "\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5WAPngyILTz"
      },
      "source": [
        "## **Run the Web**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "M4Ro5TCpnjXj"
      },
      "outputs": [],
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_bootstrap import Bootstrap5\n",
        "from flask import Flask, render_template, redirect, request, session, send_file, stream_with_context\n",
        "import os\n",
        "from werkzeug.utils import secure_filename\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvXs4r1KnO0R",
        "outputId": "c3bc81d0-c9f1-4abd-95cc-19c7e0766e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://83f1-34-138-24-102.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:07:32] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:07:32] \"\u001b[37mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:07:32] \"\u001b[37mGET /static/js/scripts.js HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:07:34] \"\u001b[37mGET /static/assets/img/bg-masthead.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:07:36] \"\u001b[37mGET /static/assets/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:07:38] \"\u001b[37mGET /download HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:07:46] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            " 90%|█████████ | 9/10 [00:18<00:02,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orig. [3.5, 2.97, 3.14, 3.18, 3.19, 3.22, 3.24, 3.32, 3.96, 4.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:08:07] \"\u001b[37mGET /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:08:07] \"\u001b[37mGET /static/js/predict.js HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:08:08] \"\u001b[37mGET /static/js/Chart.min.js HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slider [0, -1, 6, 1, 1, 0, 0, 0, 0, -1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 32.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adj. [3.5, 2.97, 3.14, 3.18, 3.19, 3.22, 3.24, 3.32, 3.96, 3.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:08:50] \"\u001b[37mPOST /adjust HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:08:50] \"\u001b[37mGET /static/js/adjust.js HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:09:05] \"\u001b[32mGET /readjust HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2022 08:09:05] \"\u001b[37mGET /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orig. [3.5, 2.97, 3.14, 3.18, 3.19, 3.22, 3.24, 3.32, 3.96, 4.76]\n"
          ]
        }
      ],
      "source": [
        "template_path = '/content/gdrive/MyDrive/碩二上/製造數據科學/MDS_Final_Project_Web_v5/templates'\n",
        "static_path = '/content/gdrive/MyDrive/碩二上/製造數據科學/MDS_Final_Project_Web_v5/static'\n",
        "\n",
        "# Downlaod file\n",
        "download_path = os.path.join(static_path, 'downloads')\n",
        "\n",
        "# Upload file\n",
        "upload_folder = os.path.join(static_path, 'uploads') # Define folder to save uploaded files to process further\n",
        "ALLOWED_EXTENSIONS = {'csv'} # Define allowed files\n",
        "\n",
        "app = Flask(__name__, template_folder = template_path, static_folder=static_path)\n",
        "app.config['UPLOAD_FOLDER'] = upload_folder # Configure upload file path flask\n",
        "app.secret_key = 'MDS Final Project Group 4' # Define secret key to enable session\n",
        "\n",
        "bootstrap = Bootstrap5(app)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "@app.route(\"/\", methods=['GET'])\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route(\"/download\")\n",
        "def downloadFile():\n",
        "    download_path = os.path.join(static_path, 'downloads/template.csv')\n",
        "    return send_file(download_path, as_attachment=True)\n",
        " \n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def uploadFile():\n",
        "    if request.method == 'POST':\n",
        "        # upload file flask\n",
        "        uploaded_df = request.files['uploaded-file']\n",
        "        # Extracting uploaded data file name\n",
        "        data_filename = secure_filename(uploaded_df.filename)\n",
        "        # flask upload file to database (defined uploaded folder in static path)\n",
        "        uploaded_df.save(os.path.join(app.config['UPLOAD_FOLDER'], data_filename))\n",
        "        # Storing uploaded file path in flask session\n",
        "        session['uploaded_data_file_path'] = os.path.join(app.config['UPLOAD_FOLDER'], data_filename)\n",
        "        return render_template('index.html')\n",
        "\n",
        "@app.route('/predict', methods=['GET', 'POST'])\n",
        "def predict():\n",
        "    global df_demo, values, hint, upper_bound\n",
        "    if df_demo.empty:\n",
        "        df_demo = pd.read_csv(os.path.join(static_path, 'uploads/df_demo.csv'), index_col='Unnamed: 0')\n",
        "        values, values_adj, hint, upper_bound = predictor(df_demo)\n",
        "\n",
        "    # predicted values   \n",
        "    values = [round(num, 2) for num in values]\n",
        "    print(\"Orig.\", values)\n",
        "    # threshold\n",
        "    threshold = [upper_bound]*10\n",
        "    # results\n",
        "    results_dict = {\"labels\": labels, \"values\": values, \"threshold\": threshold}\n",
        "\n",
        "    # anomaly hint\n",
        "    hint_item = hint.split('\\n')\n",
        "    anomaly_hint = hint_item[0]\n",
        "    for i in hint_item[1:]:\n",
        "        anomaly_hint = anomaly_hint + \", \" + i\n",
        "\n",
        "    return render_template('predict.html', results_dict=json.dumps(results_dict), anomaly=anomaly_hint)\n",
        "\n",
        "@app.route('/adjust', methods=['GET', 'POST'])\n",
        "def adjust():\n",
        "    # Get slider values\n",
        "    slider_value = []\n",
        "    for i in range(1,11):\n",
        "        slider_value.append(int(request.form.get('slider{}'.format(i))))\n",
        "    print(\"Slider\", slider_value)\n",
        "\n",
        "    adjusted_features = {\"f1\":slider_value[0], \"f2\":slider_value[1], \"f3\":slider_value[2], \"f4\":slider_value[3], \"f5\":slider_value[4], \"f6\":slider_value[5], \"f7\":slider_value[6], \"f8\":slider_value[7], \"f9\":slider_value[8], \"f10\":slider_value[9]}\n",
        "\n",
        "    # Adjustment\n",
        "    values_adj = adjuster(df_demo, slider_value)\n",
        "    values_adj = [round(num, 2) for num in values_adj]\n",
        "    print(\"Adj.\", values_adj)\n",
        "\n",
        "    results_dict = {\"labels\": labels, \"values\": values, \"values_adj\": values_adj}\n",
        "\n",
        "    return render_template('adjust.html', results_dict=json.dumps(results_dict), adjusted_features=adjusted_features)\n",
        "\n",
        "@app.route('/readjust', methods=['GET'])\n",
        "def readjust():\n",
        "    return redirect('predict')\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "    app.run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "OoUmEPpnSOWg",
        "2JAg9c8S16YP",
        "DZHjOcShGsDl",
        "NEB-Kf7KPoqg",
        "6BagFC5J9nz9",
        "UvQTx-fOKpxT",
        "r6iBhbvG-mvj"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}